<!DOCTYPE html>
<html>
<head>
  <meta name="google-site-verification" content="ilcSPlwwU8KWcf5TTPq1-xut_7sbrE9U5EuF9S1fR88" />
  <meta charset="utf-8">
  
  <title>董 燮 | Shia</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="董 燮 | Shia">
<meta property="og:url" content="http://xied1207.github.io/index.html">
<meta property="og:site_name" content="董 燮 | Shia">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="董 燮 | Shia">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link type="text/css" href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.css" rel="stylesheet">
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/scrollUp/image.css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <div class="logo">
        <img src="/logo.png" alt="Profile Picture">
      </div>
      <div id="title">董 燮 | Shia</div>
      
       <ul class="my-socials">
  
  <li>
  	<a href="https://github.com/xied1207" class="github" target="_blank">
  		<i class="fa fa-github"></i>
  	</a>
  </li>
  
  <li>
  	<a href="https://weibo.com/evetea/" class="weibo" target="_blank">
  		<i class="fa fa-weibo"></i>
  	</a>
  </li>
  
 
</ul>
    </div>
  </div>
  <div id="header-inner" class="">
    <nav id="main-nav">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <!--
        
          
            <a class="main-nav-link" href="/">首页</a>
          
            <a class="main-nav-link" href="/archives">归档</a>
          
        
      -->
    </nav>
    <nav id="title-nav" style="display:none">
      <a href="/">董 燮 | Shia</a>
      <img src="/logo.png" alt="Profile Picture">
      <!--
      <span id="title-nav-socials">
        
          <a href="https://github.com/xied1207" class="github" target="_blank">
            <i class="fa fa-github"></i>
          </a>
        
          <a href="https://weibo.com/evetea/" class="weibo" target="_blank">
            <i class="fa fa-weibo"></i>
          </a>
        
       
     </span>
      -->
    </nav>
    <nav id="sub-nav">
      
      <a id="nav-search-btn" class="nav-icon" title="Search"></a>
    </nav>
    <div id="search-form-wrap">
      <form action="http://www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
        <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="搜索">
        <input type="submit" value="" class="search-form-submit">
        <input name=tn type=hidden value="bds">
        <input name=cl type=hidden value="3">
        <input name=ct type=hidden value="2097152">
        <input type="hidden" name="si" value="xied1207.github.io">
      </form>
    </div>
  </div>
  <div class="site-nav" style="display: none;">
    <ul>
      
      
        <li><a href="/">首页</a></li>
      
        <li><a href="/archives">归档</a></li>
      
      
    </ul>
  </div>
</header>
      <div class="outer">
        <section id="main">
  

    
    <article id="post-Ng-Machine-Learning-Week-4-5-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Ng-Machine-Learning-Week-4-5-Notes/" class="article-date">
  <time datetime="2018-02-04T05:11:48.000Z" itemprop="datePublished">2018-02-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Ng-Machine-Learning-Week-4-5-Notes/">[Ng]Machine Learning Week 4-5 Notes神经网络</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><b>Model Representation 模型形式</b></p>
<p>神经元：计算单位<br>最简化的模型形式如下：<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/1.png" alt=""><br>输入层input layer-&gt;隐藏层hidden layer-&gt;输出层output layer<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/2.png" alt=""><br>a :第j层第i个激活单元<br>Θ :使j层传向j+1层的权重矩阵<br>计算激活单元的值：<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/3.png" alt=""><br>每一层都有一个权重矩阵，如图所示的权重矩阵为3×4<br>矩阵的大小为：传入层的单元数×（传出层的单元数+1）<br>多类别分类问题输出值层不是一个单元而是多个单元：<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/4.png" alt=""><br>此时分类的结果是第三类</p>
<p><b>Cost Function损失函数</b></p>
<p>L = 网络中的总层数<br>sl =第l层的单元数<br>K = 输出单元数<br>逻辑回归的损失函数为：<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/5.png" alt=""><br>基于逻辑回归的损失函数，我们可以推导出神经网络的损失函数。<br>神经网络的损失函数为：<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/6.png" alt=""><br>第一部分为对输出层每一个单元的逻辑回归损失进行累加，第二部分是整个神经网络中所有权重的平方累加</p>
<p><b>Backpropagation Algorithm反向传播算法</b></p>
<p>目的是为了使损失函数值最小-&gt;对损失函数求偏导数<br>从输出层开始计算每一层的δ（误差），δ可以用来计算偏导数<br>反向传播过程：<br>第一步：将x输入输入层<br>第二步：实现向前传播计算输出层<br>第三步：计算输出层的误差=输出值-y<br>第四步：通过反向传播计算隐藏层的误差<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/7.png" alt=""><br>并且定义：<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/8.png" alt=""><br>第五步：计算大delta，从而得到损失函数的偏导数<br><img src="/Ng-Machine-Learning-Week-4-5-Notes/9.png" alt=""><br><img src="/Ng-Machine-Learning-Week-4-5-Notes/10.png" alt=""><br>从而可以用梯度下降的方法求解</p>
<p><b>Gradient Checking梯度检查</b></p>
<p><img src="/Ng-Machine-Learning-Week-4-5-Notes/11.png" alt=""><br>当ϵ很小时，计算结果≈大delta值，可以认为反向传播算法计算正确。这种计算方法可能会非常缓慢。</p>
<p><b>Random Initialization随机初始化</b></p>
<p>不能将神经网络中的所有权重初始化为0——当进行反向传播时，所有的节点都会变成相同值，因而应当在某个值域范围内[-ϵ,ϵ]随机对权重进行赋值。</p>
<p><b>Putting it Together整合</b></p>
<p>首先，选择一个神经网络架构：确定层数，每一隐藏层有多少个单元<br>-输入单元数为特征数量<br>-输出单元数为类别数量<br>-每一隐藏层的单元数越多，模型表现越好，但是需要平衡表现与计算花费<br>-默认只有一层隐藏层，如果有多层隐藏层，最好每一隐藏层有相同的单元数</p>
<p>训练一个神经网络：<br>Step 1：随机初始化权重<br>Step 2：使用正向传播计算输出值<br>Step 3：计算损失函数<br>Step 4：使用反向传播计算偏导数<br>Step 5：通过梯度检查确定反向传播正常运行，然后不需要继续检查<br>Step 6：使用梯度下降或者其他优化函数降低损失函数值，从而找到最优的权重θ</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://xied1207.github.io/Ng-Machine-Learning-Week-4-5-Notes/" data-id="cjd8c96vv0003pcmbfu1xrl5l" class="article-share-link">分享到</a>
      

      
    </footer>
  </div>
  
</article>


    
  

    
    <article id="post-Ng-Machine-Learning-Week-3-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Ng-Machine-Learning-Week-3-Notes/" class="article-date">
  <time datetime="2018-01-30T19:53:13.000Z" itemprop="datePublished">2018-01-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Ng-Machine-Learning-Week-3-Notes/">[Ng]Machine Learning Week 3 Notes逻辑回归与正则化</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><b>Classification 分类问题</b></p>
<p>分类问题不是一个线性函数，它的输出值是几个不连续的值<br>Output y : label for the training example</p>
<p><b>Logistic Regression Model逻辑回归模型</b></p>
<p>1.Hypothesis Representation假设<br>通过变换假设的形式，使线性归回的h(x)的值域限定在[0,1]之间；对线性回归方程使用逻辑函数进行变换<br>**Sigmoid函数，i.e.逻辑函数<br>逻辑回归形式：<br><img src="/Ng-Machine-Learning-Week-3-Notes/1.png" alt=""><br>Sigmoid函数的形状：<br><img src="/Ng-Machine-Learning-Week-3-Notes/2.png" alt=""><br>通过sigmoid方程可以将任何数映射到[0,1]的范围内，此时得到的结果为输出值为1的概率（1-输出值为0的概率）</p>
<p>2.Cost Function 损失函数<br>在逻辑回归中，如果使用和线性回归一样的损失函数，会导致有多个局部最优解（简单推导可知），此时的损失函数不是一个凸函数，因为难以优化参数<br>逻辑回归的损失函数如下：<br><img src="/Ng-Machine-Learning-Week-3-Notes/3.png" alt=""><br>当y=1时，损失方程和输出值的关系为下图：<br><img src="/Ng-Machine-Learning-Week-3-Notes/4.png" alt=""><br>当y=1时，预测值越接近1，损失方程趋近于0，预测值越接近0，损失方程趋近于无限大<br>同样，当y=0时，损失方程和输出值的关系为下图：<br><img src="/Ng-Machine-Learning-Week-3-Notes/5.png" alt=""><br>当y=0时，预测值越接近0，损失方程趋近于0，预测值越接近1，损失方程趋近于无限大<br>此时我们能够确保损失函数是一个凸函数</p>
<p>3.Simplified Cost Function and Gradient Descent简化的损失函数和梯度下降<br>简化后的损失（易推导）：<br><img src="/Ng-Machine-Learning-Week-3-Notes/6.png" alt=""><br>简化后的损失函数：<br><img src="/Ng-Machine-Learning-Week-3-Notes/7.png" alt=""><br>向量表示：<br><img src="/Ng-Machine-Learning-Week-3-Notes/8.png" alt=""><br>梯度下降方法：同步下降所有的θ<br><img src="/Ng-Machine-Learning-Week-3-Notes/9.png" alt=""><br>向量化表示：<br><img src="/Ng-Machine-Learning-Week-3-Notes/10.png" alt=""></p>
<p>4.Advanced Optimization 高级参数优化方法<br>共轭下降，BFGS和LBFGS等方法<br><em>*</em>不需要自己写代码，调用package即可</p>
<p><b>Multiclass Classification多类别分类</b></p>
<p>当输出结果有n+1个类别时，y={0,1,…,n}，输出结果是概率最大的类别，如下图所示：<br><img src="/Ng-Machine-Learning-Week-3-Notes/11.png" alt=""><br>*每次选择一个类别，将其他所有类别合为一个类别，重复进行二元逻辑回归，最终选择输出概率最大的一个类别作为最终预测<br>i.e. one vs rest：<br><img src="/Ng-Machine-Learning-Week-3-Notes/12.png" alt=""></p>
<p><b>Solving the problem of overfitting 解决过拟合问题</b></p>
<p>1.The Problem of Overfitting过拟合问题<br><img src="/Ng-Machine-Learning-Week-3-Notes/13.png" alt=""><br>-简单的线性回归欠拟合underfitting，high bias<br>模型无法很好的刻画出数据的趋势，由于使用的方程太过简单或者输入的特征太少<br>-加入平方项better fit<br>-加入五次方项过拟合overfitting，high variance<br>模型无法很好的刻画出数据的趋势，假设方程很好的拟合给定的训练数据，但是当预测新的数据时表现较差。这是因为复杂的方程中产生了大量与数据本身无关的弯曲。</p>
<p>*解决过拟合问题的方法：<br>-减少特征数量：手动选择哪些变量可以保留；通过特征选择算法自动减少特征数量到合理值<br>-正则化：保有所有的特征，但是调整系数θ的大小；这种方法可以很好的应用于大量无用特征的情况下</p>
<p>2.Cost Function 损失函数<br>通过调整损失函数降低高次数项的影响：<br>函数模型：<br><img src="/Ng-Machine-Learning-Week-3-Notes/14.png" alt=""><br>损失函数（降低高次数项后）：高次项系数越大，损失越大<br><img src="/Ng-Machine-Learning-Week-3-Notes/15.png" alt=""><br><img src="/Ng-Machine-Learning-Week-3-Notes/16.png" alt=""><br>由于高次项系数较小，此方程由蓝线修正至粉线<br>正则化后损失函数的一般形式：<br><img src="/Ng-Machine-Learning-Week-3-Notes/17.png" alt=""><br>λ为正则化系数，它决定系数θ的和与损失之间的影响大小，从而可以降低过拟合问题。当λ过大时，会使曲线过于平滑，导致欠拟合underfitting，当λ太小时，没有办法使曲线平滑，依然存在过拟合overfitting</p>
<p>3.Regularized Linear Regression正则化的线性回归<br>梯度下降：<br><img src="/Ng-Machine-Learning-Week-3-Notes/18.png" alt=""><br>整理公式为：<br><img src="/Ng-Machine-Learning-Week-3-Notes/19.png" alt=""><br>正规方程：<br><img src="/Ng-Machine-Learning-Week-3-Notes/20.png" alt=""><br>4.Regularized Logistic Regression正则化的逻辑回归<br>损失函数：<br><img src="/Ng-Machine-Learning-Week-3-Notes/21.png" alt=""><br>梯度下降：<br><img src="/Ng-Machine-Learning-Week-3-Notes/22.png" alt=""></p>
<p>**进行正则化时对bias term（i.e. x0）的系数不进行正则化修正</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://xied1207.github.io/Ng-Machine-Learning-Week-3-Notes/" data-id="cjd8c96vs0002pcmbh27f72iv" class="article-share-link">分享到</a>
      

      
    </footer>
  </div>
  
</article>


    
  

    
    <article id="post-Ng-Machine-Learning-Week-2-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Ng-Machine-Learning-Week-2-Notes/" class="article-date">
  <time datetime="2018-01-29T04:20:48.000Z" itemprop="datePublished">2018-01-28</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Ng-Machine-Learning-Week-2-Notes/">[Ng]Machine Learning Week 2 Notes 多元线性回归</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><b>特征缩放 Feature Scaling</b></p>
<p>通过使输入值在差不多的范围内，从而加快梯度下降的进程：<br>-θ在x范围较小的情况下下降的较快，反之较慢，因而当输入变量的范围不平衡的时候，梯度下降过程会震荡，从而导致达到最优点的过程效率低下。如下图所示。<br><img src="/Ng-Machine-Learning-Week-2-Notes/1.png" alt=""><br>**并不是必须，但是这样能够使梯度下降的速度加快</p>
<p>特征缩放的两种方式：</p>
<ol>
<li>Feature scaling: input value/range(e.g. max-min)，因此范围被界定在-1到1之间</li>
<li>Mean normalization (x-μ)/s（μ为平均值，s为标准差，转化为正态分布）</li>
</ol>
<p><b>学习率 Learning Rate</b></p>
<p>对梯度下降进行Debug：通过绘制线图，随着每一次循环（θ下降），损失函数值是否降低。一旦损失函数有上升，我们需要减小学习率，参数α。<br>-当损失函数值小于一个threshold时我们认为已经聚拢在了最优解<br><img src="/Ng-Machine-Learning-Week-2-Notes/2.png" alt=""><br>-如果学习率α值太小，到达最优解的速度会很慢<br>-如果学习率α值太大，损失函数值可能会上升，最终无法下降到最优点<br><img src="/Ng-Machine-Learning-Week-2-Notes/3.png" alt=""><br>特征与多项式回归Features and Polynomial Regression<br>-可以通过将多个特征结合产生新的特征再进行计算<br>-如果一次线性回归模型无法很好的拟合数据，可以考虑采用/加入特征变量的平方，立法或者平方根<br><em>**</em>对于多项式回归，需要考虑特征值的范围进行缩放</p>
<p><b>正规方程Normal Equation</b></p>
<p>梯度下降之外另外一种将损失函数值最小化的方法，不需要循环语句<br>正规方程：<br><img src="/Ng-Machine-Learning-Week-2-Notes/4.png" alt=""><br>原理：求解当偏导数为0时（达到极值-&gt;最小值）的θ，通过等式变换可以得出</p>
<p>梯度下降算法：需要确定一个学习效率α，需要多次循环，问题复杂度为特征数量的平方，当特征数量较大时表现较好<br>正规方程算法：不需要确定学习效率α，不需要循环，问题复杂度为特征数量的立方（需要计算逆矩阵），当特征数量较大时运行缓慢</p>
<p>XTX不可逆时，在写代码时需要使用特殊的function，如在 octave使用 pinv而不是inv，从而在不可逆时仍然可以求解θ<br><em>**</em>不可逆的两种情况：<br>-两组特征变量非常相关（如线性相关）<br>-特征数量过大，比如大于训练样本数量<br>这些情况发生时可以按情况删去一些变量</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://xied1207.github.io/Ng-Machine-Learning-Week-2-Notes/" data-id="cjd8c96vq0001pcmb4azqkv15" class="article-share-link">分享到</a>
      

      
    </footer>
  </div>
  
</article>


    
  

    
    <article id="post-Ng-Machine-Learning-Week-1-Notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/Ng-Machine-Learning-Week-1-Notes/" class="article-date">
  <time datetime="2018-01-27T21:37:16.000Z" itemprop="datePublished">2018-01-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/Ng-Machine-Learning-Week-1-Notes/">[Ng]Machine Learning Week 1 Notes 导论与一元线性回归</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><b>What is Machine Learning?机器学习的定义</b></p>
<p>Two definitions:</p>
<p>Arthur Samuel described it as: “the field of study that gives computers the ability to learn without being explicitly programmed.” This is an older, informal definition.<br>在没有明确编程代码的情况下能够使计算机具有学习的能力。</p>
<p>Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”<br>经验+任务+表现<br>Example: playing checkers.<br>E = the experience of playing many games of checkers<br>T = the task of playing checkers.<br>P = the probability that the program will win the next game.<br>In general, any machine learning problem can be assigned to one of two broad classifications: Supervised learning and unsupervised learning 监督学习和无监督学习概念。</p>
<p><b>监督学习Supervised learning</b></p>
<p>给定数据集（含有正确的输出值，ie输出类型已知）并且已知输入变量和输出变量之间存在关联。<br>-回归问题：预测的输出类型为连续变量<br>-分类问题：预测的输出类型为分类变量</p>
<p><b>无监督学习 Unsupervised learning</b></p>
<p>输出结果的类型未知，不知道输入变量和输出变量之间的关系<br>没有办法对预测值进行衡量no feedback<br>依据变量之间的关系进行clustering聚类<br>也有非聚类的分析Non-clustering：Cocktail Party Effect<br>（鸡尾酒会效应（英语：cocktail party effect）是指人的一种听力选择能力，在这种情况下，注意力集中在某一个人的谈话之中而忽略背景中其他的对话或噪音。 该效应揭示了人类听觉系统中令人惊奇的能力，使我们可以在噪声中谈话。）</p>
<p><b>代价方程/损失方程 Cost Function</b></p>
<p>用以衡量假设方程的准确度<br><img src="/Ng-Machine-Learning-Week-1-Notes/1.png" alt=""><br>i.e. 平方误差函数，均方误差<br>1/2是为了方便梯度下降计算<br>选择θ0和θ1能够使J最小，从而找到合适的参数</p>
<p><img src="/Ng-Machine-Learning-Week-1-Notes/2.png" alt=""><br>图解：同一个环形上θ0和θ1的组合的J相同。最中间的圆心是result（最优解）</p>
<p><b>梯度下降 Gradient Descent</b></p>
<p><img src="/Ng-Machine-Learning-Week-1-Notes/3.png" alt=""><br>用以估计最佳拟合的θ0和θ1<br>Θ0和θ1沿切线下降，系数α决定了每一步下降多少，下降方向由代价方程的偏导数决定<br>不同的起点会最终下降到不同的地方</p>
<p><img src="/Ng-Machine-Learning-Week-1-Notes/4.png" alt=""><br>梯度下降算法中需要注意，θ0和θ1需要同步更新</p>
<p><img src="/Ng-Machine-Learning-Week-1-Notes/5.png" alt=""><br>当偏导数为正时，参数估计值会变小；偏导数为负时，参数估计值变大，从而是参数估计值趋向于最优解（minimum value）</p>
<p><img src="/Ng-Machine-Learning-Week-1-Notes/6.png" alt=""><br>通过调整系数α使梯度下降算法在合理的时间内完成：<br>每一步太小：耗时过长<br>每一步太大：错过最优解（无法聚合）</p>
<p><img src="/Ng-Machine-Learning-Week-1-Notes/7.png" alt=""><br>在梯度下降的过程中（聚合的过程中），当接近最优点的时候随着偏导数越来越小，每一步下降的量也会不断减小，所以不需要调整α。</p>
<p><b>线性回归的梯度下降 Gradient Descent For Linear Regression</b></p>
<p><img src="/Ng-Machine-Learning-Week-1-Notes/8.png" alt=""></p>
<p>推导过程：<br><img src="/Ng-Machine-Learning-Week-1-Notes/9.png" alt=""><br>**对于第二步，此时θ0的偏导数为1，θ1的偏导数为Xj<br>对于线性回归问题，只存在一个全局最优解，不存在局部最优解</p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://xied1207.github.io/Ng-Machine-Learning-Week-1-Notes/" data-id="cjd8c96vl0000pcmbhmzzdeh0" class="article-share-link">分享到</a>
      

      
    </footer>
  </div>
  
</article>


    
  

    
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/hello-world/" class="article-date">
  <time datetime="2018-01-23T20:12:41.000Z" itemprop="datePublished">2018-01-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/hello-world/">hello-world</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>A brand-new personal space built on Github;<br>Using for blogging data science study/industry insights/lessons learned;<br>All reserved by Shia Dong(董燮);</p>
<p>Thanks to tutorial:<br><a href="http://yuweiguocn.github.io/tags/hexo/" target="_blank" rel="noopener">http://yuweiguocn.github.io/tags/hexo/</a><br><a href="https://hexo.io/docs/" target="_blank" rel="noopener">https://hexo.io/docs/</a><br>Thanks to theme from：<br><a href="https://github.com/henryhuang/oishi" target="_blank" rel="noopener">https://github.com/henryhuang/oishi</a></p>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://xied1207.github.io/hello-world/" data-id="cjd8c96vy0004pcmbydiv7app" class="article-share-link">分享到</a>
      

      
    </footer>
  </div>
  
</article>


    
  
  
</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 Shia Dong<br>
      Theme <a href="https://github.com/henryhuang/oishi" target="_blank">Oishi</a>, Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <!--
      <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="/archives" class="mobile-nav-link">归档</a>
  
</nav>
    -->
    

<!-- 百度分享 start -->

<!-- 百度分享 end -->

<script src="//cdn.bootcss.com/jquery/1.11.1/jquery.min.js"></script>



<script src="/js/jquery.scrollUp.min.js"></script>
<script src="/js/jquery.transform.js"></script>
<script src="/js/menu.js"></script>

<script src="/js/script.js"></script>
<script src="/js/scrollUp.js"></script>

  </div>
</body>
</html>